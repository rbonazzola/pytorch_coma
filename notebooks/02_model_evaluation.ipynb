{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-09 14:58:26,079 [INFO] No OpenGL_accelerate module loaded: No module named 'OpenGL_accelerate'\n"
     ]
    }
   ],
   "source": [
    "import os, shlex\n",
    "from subprocess import check_output\n",
    "\n",
    "# go to the root of the repository\n",
    "repo_rootdir = check_output(shlex.split(\"git rev-parse --show-toplevel\")).strip().decode('ascii')\n",
    "os.chdir(repo_rootdir)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "from config.config_parser import read_config\n",
    "from utils.helpers import *\n",
    "\n",
    "import utils.mesh_operations\n",
    "device = get_device()\n",
    "from IPython.display import display\n",
    "\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import pyvista as pv\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import numpy\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select experiment\n",
    "An \"experiment\" is an instance of training for a specific model. Each experiment has a folder associated in the \"output\" folder. These folders' names are just timestamps, by default. The associated configuration (network architecture, input data, random seed, training parameters, etc.) can be seen in a file called config.json that is located inside the experiment's folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a56bcbba2b4c4b1cbd896f77dd129322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Experiment:', options=('2020-09-03_16-58-02', '2020-09-09_13-24-32', '2020-09-10_02-46-2â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_dir = \"output\"\n",
    "\n",
    "experiments = [\n",
    "  x for x in sorted(os.listdir(output_dir)) \n",
    "    if os.path.exists(os.path.join(output_dir, x, \".finished\")) # just a workaround to check if the training finished\n",
    "]\n",
    "\n",
    "w = widgets.Dropdown(\n",
    "    options=experiments,\n",
    "    description='Experiment:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "display(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-09 14:58:49,189 [ERROR] Unsupported point attribute type: point_data for file: ./template/template.vtk\n"
     ]
    }
   ],
   "source": [
    "import ExperimentClass\n",
    "\n",
    "# Load experiment\n",
    "experiment = ExperimentClass.ComaExperiment(os.path.join(output_dir, w.value))\n",
    "experiment.load_model() # load a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_function': 'relu',\n",
      " 'batch_size': 16,\n",
      " 'checkpoint_file': 'output/test_2020-09-11_01-49-33/checkpoints/checkpoint_117.pt',\n",
      " 'comments': '',\n",
      " 'data_dir': 'data/meshes/numpy_files/LV_all_subjects/train.npy',\n",
      " 'downsampling_factors': [4, 4, 3, 2],\n",
      " 'epoch': 118,\n",
      " 'eval': False,\n",
      " 'group_label': '',\n",
      " 'ids_file': 'data/meshes/numpy_files/LV_all_subjects/LVED_all_subjects_subj_ids.txt',\n",
      " 'kld_weight': 0.01,\n",
      " 'label': '',\n",
      " 'learning_rate': 0.5,\n",
      " 'learning_rate_decay': 0.99,\n",
      " 'nTraining': 5000,\n",
      " 'nVal': 1000,\n",
      " 'n_layers': 4,\n",
      " 'num_conv_filters': [3, 16, 16, 16, 32, 32],\n",
      " 'optimizer': 'adam',\n",
      " 'output_dir': 'output/{TIMESTAMP}',\n",
      " 'partition': 'LV',\n",
      " 'polygon_order': [6, 6, 6, 6, 6],\n",
      " 'preprocessed_data': 'data/transforms/cached/2ch_segmentation__LV__ED__scaled.pkl',\n",
      " 'procrustes_scaling': True,\n",
      " 'procrustes_type': 'generalized',\n",
      " 'reconstruction_loss': 'l1',\n",
      " 'run_id': '2020-09-11_02-13-41',\n",
      " 'template_fname': './template/template.vtk',\n",
      " 'test': False,\n",
      " 'visual_output_dir': '',\n",
      " 'visualize': False,\n",
      " 'weight_decay': 0.0005,\n",
      " 'weight_loss': '0',\n",
      " 'workers_thread': 8,\n",
      " 'z': 8}\n"
     ]
    }
   ],
   "source": [
    "# print configuration for the experiment selected\n",
    "pprint(experiment.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load mesh data used for the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-aligned meshes\n",
    "prealigned_meshes = experiment.load_prealigned_meshes()\n",
    "dataloader = get_loader(prealigned_meshes.point_clouds, prealigned_meshes.ids, batch_size=8, num_workers=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruct meshes from specific subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a dictionary mapping subject ID with the position of the corresponding mesh in the array\n",
    "id_dict = {k:v for v,k in enumerate(prealigned_meshes.ids)}\n",
    "\n",
    "def get_mesh_for_id(dataloader, id, id_dict):\n",
    "    position = id_dict[id]\n",
    "    return dataloader.dataset[position][0].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wcb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ed04455b8af5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m interact(f, \n\u001b[0;32m---> 33\u001b[0;31m   \u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwcb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m   \u001b[0mreconstructed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m   \u001b[0mdeviation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wcb' is not defined"
     ]
    }
   ],
   "source": [
    "def reconstruct(experiment, mesh):\n",
    "    model = experiment.model\n",
    "    with torch.no_grad():\n",
    "        if model.is_variational:\n",
    "            mu, log_var = model.encoder(x=mesh)\n",
    "            z = mu\n",
    "        else:\n",
    "            z = model.encoder(x=mesh)\n",
    "        mesh_r = model.decoder(z)\n",
    "    return mesh_r\n",
    "\n",
    "\n",
    "\n",
    "def plot_mesh(mesh):\n",
    "  kargs = {\"point_size\": 5, \"render_points_as_spheres\": True}\n",
    "  plotter = pv.Plotter(notebook=True)\n",
    "  plotter.add_mesh(mesh, **kargs)\n",
    "  plotter.show(interactive=True)\n",
    "  plotter.enable()\n",
    "\n",
    "\n",
    "\n",
    "def f(id, reconstructed=True, deviation=True):\n",
    "  try:\n",
    "    mesh = get_mesh_for_id(dataloader, id, id_dict)\n",
    "    _mesh = reconstruct(experiment, mesh) if reconstructed else mesh\n",
    "    _mesh = _mesh.detach().numpy() if deviation else prealigned_meshes.mean + prealigned_meshes.std * _mesh.detach().numpy()\n",
    "    plot_mesh(_mesh.squeeze(0))\n",
    "  except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Select a spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcb=widgets.Combobox(\n",
    "    placeholder=\"Choose a subject\",\n",
    "    options=sorted(prealigned_meshes.ids),\n",
    "    value=\"1000336\"\n",
    ")\n",
    "interact(f, \n",
    "  id=wcb,\n",
    "  reconstructed=True,\n",
    "  deviation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create synthetic meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_from_z(experiment, z):\n",
    "    model = experiment.model\n",
    "    with torch.no_grad():\n",
    "        mesh_r = model.decoder(z)\n",
    "    return mesh_r    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(z0, z1, z2, z3, z4, z5, z6, z7, deviation=True):\n",
    "    \n",
    "    z = torch.Tensor([z0, z1, z2, z3, z4, z5, z6, z7])    \n",
    "    mesh = reconstruct_from_z(experiment, z.unsqueeze(0)) # get_mesh_for_id(dataloader, id, id_dict)\n",
    "    _mesh = mesh.detach().numpy() if deviation else prealigned_meshes.mean + prealigned_meshes.std * mesh.detach().numpy()\n",
    "    plot_mesh(_mesh.squeeze(0))\n",
    "\n",
    "z_sliders = {\"z\"+str(i):widgets.FloatSlider(value=0, min=-3, max=3, step=1) for i in range(experiment.config['z'])}\n",
    "\n",
    "interact(g, \n",
    "  **z_sliders,\n",
    "  deviation=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
